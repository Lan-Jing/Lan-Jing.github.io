---
title: "Parallel Computing: dbcsr (Presentation Note)"
categories:
  - Parallel Computing
  - Competition
---

CP2K is my optimization target in the second [cas-pra](https://cas-pra.sugon.com/) competition. This is the presentation note after some study on dbcsr, the sub-program for optimized sparse matrix-matrix multiplications.

## Distributed Blocked Compressed Sparse Row

### CP2K

先导杯我负责的题目。前后花了一个多星期的样子，目前已经成功部署。小算例上显卡就有三倍优化、大算例目前上卡没有任何作用。大算例没用的问题在dbcsr的GPU调度占比太低，打算先试着解决这个问题。

目标的优化方向：

* 子模块、编译优化：各种编译选项试一试，可选的优化数学库试一试：libint, libxc, **libxsmm**
* 代码优化：大部分主程序真的有难度，需要学fortran一套；上卡部分有CUDA代码，做优化比较方便，但是优化空间未知
* 算法、系统层面优化：结合硬件？集群、调度、数据存储、表示方面的优化……

### GPU-Accelerated DBCSR

CP2K的一部分，目前已经是独立的项目了。DBCSR上卡对小算例有明显优化，对大算例没有效果。

#### ARCH

* Linear Scaling SCF：迭代的算法。
* 稀疏，但又不完全稀疏（<50%）-> 多个backends: BLAS, libsmm

![DBCSR ARCH]({{ site.url }}{{ site.baseurl }}/assets/images/dbcsr%20arch.png){: .align-center}
  
* Compressed Sparse Row(CSR)
* Cannon's Algorithm for **inter-node** Matrix-Matrix Multiplications, using MPI
* **intra-node** Multiplications with OpenMP

![Cannon's Algorithm]({{ site.url }}{{ site.baseurl }}/assets/images/cannon.png){: .align-center}

#### Multrec

* 为了实现cache友好，而不需要写很多丑陋的分块代码
* 感觉类似strassen的递归矩阵乘法
* 递归划分矩阵，使得矩阵足够小能够放进cache里面

#### CSR

* stacks：将（同类）索引首先放到存储结构里面，然后统一提交到CPU/GPU进行计算。将索引和计算两种操作分离，对cache和GPU都更友好
* Filtering：假设一个子矩阵C(i, j)计算结果的最大误差为e，A(i, \*)分为n个子矩阵。那么每个子矩阵就能分配到最多e/n误差，如果\|\|A(i, k)\|\| * \|\|B(k, j)\|\| < e/n，那么直接不乘这个矩阵。保持矩阵的稀疏特性的同时，大大减少计算量

#### CPU/GPU Scheduler

* 稀疏运算，GPU对CPU没有太大优势 -> 调度器，同时利用CPU和GPU进行计算
* Host Drivers: libsmm/lixsmm
* CUDA Drivers: Streams and Events，最大限度做到并发，隐藏调度、数据传输（CPU-CPU/CPU-GPU）的开销
* 双buffer：多个CPU threads争抢显卡。每个thread的高优先级任务只有有限的配额。显卡先处理高优先级的buffer，后处理低优先级buffer
