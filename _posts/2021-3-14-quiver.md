---
title: "AI, System: Quiver, A Distributed Cache For Deep Learning"
categories:
  - AI
  - System
---

By Abhishek Vijaya Kumar and Muthian Sivathanu from Microsoft Research India. 

The usual deep learning framework like Pytorch, requests *mini-batches* from the global storage in each iteration. A *mini-batch* is consumed by the GPUs then **discarded immediately**, meaning that a reload is required in the following epochs. Worse, multiple machines may access the same dataset simultaneously(e.g., hyper-parameter tuning), causing the remote storage to become a bottleneck of the whole system.

But we can use the local SSD in each compute node. Quiver, is a distributed SSD cache system to increase data locality and ease IO stress in such workload.

## I/O Characteristics of DLT

Below is the critical observation of how typical distributed machine learning systems consume IO resources. Quiver is designed to take advantage of these.

* Shareability: Data samples are shared across multiple epochs in a single job and across jobs that use the same dataset. This property ensures that caching data is likely to be an improvement.
* Random Access: In each epoch, a dataset is accessed in the order of a random permutation. Thus it is very likely that a cache miss happens if the dataset can not fit in the SSD.
* Substitutability: However, we can cheat the trainer by **giving whatever is in the cache** to the framework, as long as randomness is enforced and each data sample is iterated *exactly once* in an epoch. 
* Predictability: If the model is configured, GPUs are good, then the time needed for each mini-batch is typically constant. We can use this property to estimate what improvement our caching strategy can reach.

![struct]({{ site.url }}{{ site.baseurl }}/assets/images/quiver.png){: .align-center}

## Substitutable Hits

Remember that we can feed whatever is in the cache. Quiver achieve minimal cache miss by doing substitutable hits. In particular, the dataloader will lookup much more indices than a mini-batch it needs(say 10x). This usually make sure that the cache system has enough data samples to return. After that, those indices not appeared in the cache will be marked as *pending*, and requested later by the dataloader to replace what is currently in the local storage.