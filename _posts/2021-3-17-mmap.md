---
title: "System: mmap, Memory Mapped IO"
categories:
  - System
---

Memory-mapped IO through Linux **mmap** command is fundamental to many critical techniques in systems programming. For instance, MPI could use mmap to implement fast communication between processes *within a node*. In-memory file systems require mmap and, optimizations are studied to improve IO with the secondary storage. This blog covers several naive concepts on how mmap works.

## mmap

The **mmap** command of Linux establishes a mapping between a virtual memory area and a segment of physical memory. The mapping can set as backed by a file stored in a block device or initialized as empty. In the first situation, we can conduct read/write operations to a file just like an array of chars. Mutations are flushed back to disk in an *asynchronous* manner. When that memory is not backed by a file, it can be set as *shared memory* for data exchange between processes.

When a process calls the mmap command, a *virtual memory area* is created to allocate the required virtual space. At this point, **no physical memory** is reserved for this mapping, so the mapping itself is empty. That is to say, the process is only **granted** to see that virtual space and the actual mapping is established *lazily* through the Linux **page fault** mechanism.

When you access the backed file through this mapping, the page table is referenced. The system should search the existence of the mapping between the virtual address and the physical position of the data. Keep in mind that initially, no mapping is there, so a *page fault* exception is triggered. Now the kernel takes control, fetches the missing page from the storage, and places it in memory. Then the mapping is finally set in the page table.

![mmap]({{ site.url }}{{ site.baseurl }}/assets/images/mmap.png){: .align-center}

And why mmap provides quick IO(especially read)? Because of the **page cache** in the Linux *virtual file system*. Since I/O through the secondary storage is terribly slow, The Linux kernel maintains(in the kernel space) a page cache to cache data blocks that are repeatedly requested. In a cache miss, a data block is first moved to the page cache, then to the userspace. However, in a *page fault* situation, that data block is copied directly, saving one copy in the kernel space.

## Shared Memory Communication


## In-memory File Systems

## References

Choi, Jungsik, Jiwon Kim, and Hwansoo Han. "Efficient memory mapped file I/O for in-memory file systems." 9th {USENIX} Workshop on Hot Topics in Storage and File Systems (HotStorage 17). 2017.